#!/usr/bin/env python

import json
import sys

import boto3
from rich.console import Console

bedrock = boto3.client("bedrock-runtime")
console = Console()


def claude(prompt):
    with console.status("[bold green]Waiting for response..."):
        response = bedrock.invoke_model_with_response_stream(
            modelId="anthropic.claude-v2",
            body=json.dumps(
                {
                    "prompt": prompt,
                    "max_tokens_to_sample": 300,
                    "temperature": 1,
                    "top_k": 250,
                    "top_p": 0.999,
                    "stop_sequences": ["\n\nHuman:"],
                    "anthropic_version": "bedrock-2023-05-31",
                }
            ),
        )

    return response["body"]


def main():
    context = ""

    print("Hello! I am an AI assistant. Enter 'quit' or 'exit' at any time to exit. How may I help you today?")

    while True:
        print()
        if context == "" and len(sys.argv) > 1:
            user_input = " ".join(sys.argv[1:])
            print(f"> {user_input}")
        else:
            user_input = input("> ")

        print()
        if user_input.lower() == "quit" or user_input.lower() == "exit":
            print("Goodbye!")
            sys.exit()

        prompt = f"{context}\n\nHuman: {user_input}\n\nAssistant:"
        stream = claude(prompt)

        response = ""
        for raw_event in stream:
            event = json.loads(raw_event["chunk"]["bytes"])
            output = event["completion"]
            response += output
            print(output, end="")

        print()
        context += f"\n\nHuman: {user_input}\n\nAssistant: {response}"


if __name__ == "__main__":
    main()
